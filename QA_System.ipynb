{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QA- System",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ArZ7hoVk0-Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7b20d0c4-b5d0-48f5-e270-e75592ff852e"
      },
      "source": [
        "#importing the required packages\n",
        "import nltk\n",
        "nltk.download('all')\n",
        "import re\n",
        "import string\n",
        "import gensim \n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "from nltk import sent_tokenize, word_tokenize\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy import spatial\n",
        "from nltk import pos_tag,word_tokenize,ne_chunk\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from pandas import DataFrame\n",
        "\n",
        "from nltk.corpus import wordnet,stopwords\n",
        "import spacy\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3kTgL0Qk6tn",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "bb6529da-d0bc-4fe7-bb11-f4610f0bb54a"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded=files.upload()\n",
        "#sample = open(\"COVID19_wikipedia article.txt\", \"r\") \n",
        "sample = open(\"c.txt\", \"r\")\n",
        "s = sample.read() \n",
        "s=s.replace(\"COVID 19\",\"coronavirus\")\n",
        "#s='''The Amazon rainforest (Portuguese: Floresta Amazônica or Amazônia; Spanish: Selva Amazónica, Amazonía or usually Amazonia; French: Forêt amazonienne; Dutch: Amazoneregenwoud), also known in English as Amazonia or the Amazon Jungle, is a moist broadleaf forest that covers most of the Amazon basin of South America. This basin encompasses 7,000,000 square kilometres (2,700,000 sq mi), of which 5,500,000 square kilometres (2,100,000 sq mi) are covered by the rainforest. This region includes territory belonging to nine nations. The majority of the forest is contained within Brazil, with 60% of the rainforest, followed by Peru with 13%, Colombia with 10%, and with minor amounts in Venezuela, Ecuador, Bolivia, Guyana, Suriname and French Guiana. States or departments in four nations contain \"Amazonas\" in their names. The Amazon represents over half of the planet's remaining rainforests, and comprises the largest and most biodiverse tract of tropical rainforest in the world, with an estimated 390 billion individual trees divided into 16,000 species.'''\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-439ce9b5-4cbb-4ab3-ad4f-5259340cc8ee\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-439ce9b5-4cbb-4ab3-ad4f-5259340cc8ee\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving c.txt to c.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNjJvOtSk7bs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stem_sentence(sentence):\n",
        "  words=word_tokenize(sentence)\n",
        "  #lemmatizer = WordNetLemmatizer()\n",
        "  \n",
        "  \n",
        "  stemmer = SnowballStemmer(\"english\")\n",
        "  new_words=[]\n",
        "  for i in words:\n",
        "    new_words.append(stemmer.stem(i))\n",
        "    new_words.append(\" \")\n",
        "  return \"\".join(new_words)  \n",
        "  \n",
        "\n",
        "\n",
        "def clean_sentence(sentence, stopwords=True):\n",
        "    \n",
        "    sentence = sentence.lower().strip()\n",
        "    sentence = re.sub(r'[^a-z0-9\\s]', '', sentence)\n",
        "    \n",
        "    \n",
        "    \n",
        "    if stopwords:\n",
        "         sentence = remove_stopwords(sentence)\n",
        "    \n",
        "   \n",
        "    \n",
        "    return sentence\n",
        "def get_cleaned_sentences(sents,stopwords=True):    \n",
        "    \n",
        "    cleaned_sentences=[]\n",
        "\n",
        "    for i in sents:\n",
        "        \n",
        "        cleaning=clean_sentence(i,stopwords)\n",
        "        cleaned=stem_sentence(cleaning)\n",
        "        cleaned_sentences.append(cleaned)\n",
        "    return cleaned_sentences\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFQbswivlAlp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_document_term_matrix(sen,vectorizer):\n",
        "  doc_term_matrix=vectorizer.fit_transform(sen)\n",
        "  return DataFrame(doc_term_matrix.toarray(), columns=vectorizer.get_feature_names())\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28eA0yL0lFL7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_cosine_similarity(df_list,sentences,question):\n",
        "  a=[]\n",
        "  for i in range(len(df_list)-1):\n",
        "    sim=1 - spatial.distance.cosine(df_list[i], question)\n",
        "    t=(sim,sentences[i])\n",
        "    a.append(t)\n",
        "  a.sort(reverse=True)\n",
        "  n=[]\n",
        "  for i in range(3):\n",
        "    n.append(a[i][1])\n",
        "    print(\"*\",n[i])\n",
        "   \n",
        "    \n",
        "  return n  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRYoXgLYlNSD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def determineQuestionType( question):\n",
        "        questionTaggers = ['WP','WDT','WP$','WRB']\n",
        "        question_POS = pos_tag(word_tokenize(question.lower()))\n",
        "        \n",
        "        question_Tags=[]\n",
        "        for token in question_POS:\n",
        "            if token[1] in questionTaggers:\n",
        "              question_Tags.append(token)\n",
        "                \n",
        "                \n",
        "        if len(question_Tags)==1 and question_Tags[0][0]!= 'what' :\n",
        "          return True\n",
        "        else:\n",
        "          return False  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Cli_jJ0lONW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.util import ngrams\n",
        "def n_gram_similarity(question,n):\n",
        "  q=list(ngrams(word_tokenize(question.lower()),1))\n",
        "  a=0\n",
        "  b=0\n",
        "  c=0\n",
        "  t=[]\n",
        "  for i in q:\n",
        "    if i in list(ngrams(word_tokenize(n[0].lower()),1)):\n",
        "      a=a+1\n",
        "  for i in q:\n",
        "    if i in list(ngrams(word_tokenize(n[1].lower()),1)):\n",
        "      b=b+1\n",
        "  for i in q:\n",
        "    if i in list(ngrams(word_tokenize(n[2].lower()),1)):\n",
        "      c=c+1        \n",
        "  d=max(a,b,c)\n",
        "  if a == d:\n",
        "    t.append(n[0])\n",
        "  if b == d:\n",
        "    t.append(n[1]) \n",
        "  if c ==d:\n",
        "    t.append(n[2])\n",
        "  print()  \n",
        "  #print(\"Selected Sentence:\",t[0])  \n",
        "  return t  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKBe8u5slTdA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def answertype(question):\n",
        "  nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "  if (determineQuestionType(question)):\n",
        "    t='DESCRIPTIVE'\n",
        "    flag=0\n",
        "    word=word_tokenize(question.lower())\n",
        "  \n",
        "    if 'who' in word:\n",
        "      t='PERSON'\n",
        "    elif 'where' in word:\n",
        "      t='GPE'\n",
        "    elif 'how' in word and 'many' in word and  'age' in word or 'duration' in word or 'long' in word or 'days'in word or 'years' in word or'months' in word:\n",
        "      t='DATE' \n",
        "    elif 'how' in word and 'many' in word :\n",
        "       t = 'CARDINAL'  \n",
        "    elif 'when' in word  or 'age' in word or 'period' in word or 'duration' in word  or 'old' in word or 'long' in word:\n",
        "      t='DATE'\n",
        "    elif 'how' in word  and 'long' in word or 'often' or 'age' in word or 'years' in word:\n",
        "      t='DATE' \n",
        "    elif 'what' in word and 'time' in word or 'duration' in word or 'period' in  'word'  :\n",
        "      t='DATE' \n",
        "    i=len(df_list)-1  \n",
        "    n=calculate_cosine_similarity(df_list, sentences,df_list[i])\n",
        "    n=n_gram_similarity(question,n)\n",
        "    #print(\"Most relevant sentence\", n[0])\n",
        "    #print(\"ANSWER TYPE:\",t)\n",
        "    key = n[0]\n",
        "    spdoc = nlp(key)\n",
        "    entity_type=[]\n",
        "    for ent in spdoc.ents:\n",
        "       if ent.label_ == t:\n",
        "          entity_type.append(ent.text)\n",
        "    if len(entity_type) == 1:\n",
        "      print(\"ANSWER TYPE:\", t)\n",
        "      print(\"ANSWER:\", entity_type[0])  \n",
        "    if len(entity_type) == 0:\n",
        "      print(\"ANSWER TYPE:\", t) \n",
        "      print(n[0])\n",
        "    if len(entity_type) > 1:\n",
        "      print(\"Answer Type:\",t)  \n",
        "      key_question = question\n",
        "      q=[]\n",
        "      spdoc = nlp(key_question)\n",
        "      for ent in spdoc:\n",
        "        if ent.pos_ == 'NOUN' or ent.pos_ =='ADJ' :\n",
        "          q.append(ent.text)\n",
        "  \n",
        "      key_answer = n[0]\n",
        "      a = []\n",
        "      spd = nlp(key)\n",
        "      for ent in spd:\n",
        "        if ent.pos_ == 'NOUN'or ent.pos_ =='ADJ' :\n",
        "          a.append(ent.text)\n",
        "  #s=[sentence.index(i) for i in t]\n",
        "      s=[]\n",
        "      w=[]\n",
        "      for i in entity_type:\n",
        "       s.append(n[0].index(i))\n",
        "      for i in range(len(s)):\n",
        "        w.append(0)\n",
        "\n",
        "    \n",
        "      for i in q:\n",
        "        try:\n",
        "           factor= n[0].index(i)\n",
        "           for j in range(len(s)):\n",
        "              w[j]=w[j]+(abs(s[j]-factor))\n",
        "        except:\n",
        "           continue    \n",
        "      m=min(w)\n",
        "      u=[]\n",
        "      for i in range(len(s)):\n",
        "        if w[i] == m:\n",
        "           #print(entity_type[i])\n",
        "           u.append(entity_type[i])\n",
        "      print(\"ANSWER:\",u[0])     \n",
        "      \n",
        "\n",
        "  \n",
        "\n",
        "    \n",
        "  else:\n",
        "    t='DESCRIPTIVE'\n",
        "    print(\"ANSWER TYPE:\",t)\n",
        "    i=len(df_list)-1  \n",
        "    n=calculate_cosine_similarity(df_list, sentences,df_list[i])\n",
        "    #n = n_gram_similarity(question, n)\n",
        "    for j in n:\n",
        "         print(j) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1r9nOcqlezX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2dc94fe5-0809-4151-b777-f023c060e75d"
      },
      "source": [
        "#question=[\"What preventive measures should I take?\",\"How does the virus spread?\",\"How many days is the incubation period of the virus?\",\"When was COVID-19 declared a health emergency?\",\"When was COVID-19 declared a pandemic?\",\"How many deaths have occured in various countries?\",\"How apart should people stay?\",\"What is the time between exposure to onset of symptoms?\",\"Where was COVID-19 first identified?\",\"Is it necessary to cover my face?\",\"Should I cover my face?\",\"When the did the first case of COVID-19 occur in Delhi ?\",\"what was the age of the first patient in Delhi?\", \"Where has the  virus been found in wastewater?\",\"How many cases have been reported?\",\"What facemasks should I use?\",\"What method is used for diagnosis?\",\"How old was the first patient in Delhi?\",\"What about the vaccine?\",\"How many days is the incubation period of the virus?\",\"How long do the affected persons remain infectious?\",\"Does loss of smell also occur?\",\"When did World health organization declare coronavirus a world pandemic?\",\"How many people have recovered?\"]\n",
        "#question=[\"What is Zealandia?\", \"How many years ago did Zealandia subside?\",\"In which ocean is Zealandia submerged?\",\"When were permits for oil exploration in the Great South Basin issued?\"]\n",
        "#question=[\"Where did Black Death originate?\",\"How did the black death make it to the Mediterranean and Europe?\",\"How much of the European population did the black death kill?\",\"When did the world's population finally recover from the black death?\",\"For how long did the plague stick around?\",\"When did the Black Death originate in Central Asia?\",\"In what year did the Black Death reach the Mediterranean?\"]\n",
        "#question=[\"How many people were in French North American Colonies?\",\"Who fought in the French and Indian war?\",\"How many people were in French North American Colonies?\",\"How many people were in British North American Colonies?\",\"When was the French and Indian War?\"]\n",
        "question=[\"Where was the virus first identified?\",\"When was the virus first identified?\",\"When did the first case occur in Delhi?\",\"How many days is the incubation period of the virus?\",\"When was COVID-19 declared a health emergency?\",\"When was COVID-19 declared a pandemic?\",\"How apart should people stay?\",\"How many people have recovered till now?\",\"How many cases have been reported?\",\"How many deaths have occured in various countries?\",\"In how many World Health Organization zones local transmission has occuerd?\",\"Cases have been reported in how many countries?\",\"How many countries have reported cases?\",\"How long should I wash my hands?\",\"What are the common symptoms of COVID-19?\",\"What type of masks should I wear?\"]\n",
        "\n",
        "#question=[\"Which name is also used to describe the Amazon rainforest in English?\",\"How many square kilometers of rainforest is covered in the basin?\",\"How many nations control this region in total?\",\"How many nations contain Amazonas in their names?\",\"What percentage does the Amazon represents in rainforests on the planet?\",\"How many square kilometers is the Amazon Basin?\",\"How many nations are within the Amazon Basin?\",\"How many tree species are there in the amazon tropical rain forest?\"]\n",
        "for j in question:\n",
        "  que=sent_tokenize(j)\n",
        "  sentences=sent_tokenize(s)\n",
        "  #q contains a list of cleaned sentence tokens of question\n",
        "  q=get_cleaned_sentences(que,stopwords=True)\n",
        "  #preprocessed contains a list of cleaned sentence tokens of the reference text\n",
        "  preprocessed=get_cleaned_sentences(sentences,stopwords=True)\n",
        "  \n",
        "  preprocessed.append(q[0])\n",
        "  i=len(preprocessed)-1\n",
        "  print(\"QUESTION:\",j)\n",
        "  \n",
        "  tfidf_vect=TfidfVectorizer()\n",
        "  df=create_document_term_matrix(preprocessed,tfidf_vect) \n",
        "  df_list = df.values.tolist()\n",
        "  answertype(j)\n",
        "  print()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "QUESTION: Where was the virus first identified?\n",
            "* It was first identified in December 2019 in Wuhan, China, and has resulted in an ongoing pandemic.\n",
            "* On surfaces the amount of active virus decreases over time until it can no longer cause infection, and surfaces are thought not to be the main way the virus spreads.\n",
            "* People can transmit the virus without showing symptoms, but it is unclear how often this happens.\n",
            "\n",
            "Answer Type: GPE\n",
            "ANSWER: Wuhan\n",
            "\n",
            "QUESTION: When was the virus first identified?\n",
            "* It was first identified in December 2019 in Wuhan, China, and has resulted in an ongoing pandemic.\n",
            "* On surfaces the amount of active virus decreases over time until it can no longer cause infection, and surfaces are thought not to be the main way the virus spreads.\n",
            "* People can transmit the virus without showing symptoms, but it is unclear how often this happens.\n",
            "\n",
            "ANSWER TYPE: DATE\n",
            "ANSWER: December 2019\n",
            "\n",
            "QUESTION: When did the first case occur in Delhi?\n",
            "* Transmission without symptoms does occur.\n",
            "* Total 92 contacts of Delhi index case have been traced.\n",
            "* The first case of coronavirus at Delhi was confirmed on 2nd March when a 45 years old person from East Delhi, with a history of travel from Italy, has been tested to be positive for COVID-19.\n",
            "\n",
            "Answer Type: DATE\n",
            "ANSWER: 2nd March\n",
            "\n",
            "QUESTION: How many days is the incubation period of the virus?\n",
            "* This is called the incubation period.\n",
            "* The typical incubation period for coronavirus is five or six days, but it can range from one to fourteen days with approximately ten percent of cases taking longer.\n",
            "* It is unknown what amount of virus on surfaces is required to cause infection via this method, but it can be detected for up to four hours on copper, up to one day on cardboard, and up to three days on plastic (polypropylene) and stainless steel (AISI 304).\n",
            "\n",
            "Answer Type: DATE\n",
            "ANSWER: five or six days\n",
            "\n",
            "QUESTION: When was COVID-19 declared a health emergency?\n",
            "* The World Health Organization (WHO) declared the coronavirus outbreak a public health emergency of international concern (PHEIC) on 30th January 2020 and a pandemic on 11th March 2020.\n",
            "* According to the World Health Organization (WHO), there are no vaccines nor specific antiviral treatments for COVID-19.\n",
            "* Out of 14 contacts two were symptomatic and found negative for COVID-19.\n",
            "\n",
            "Answer Type: DATE\n",
            "ANSWER: 30th January 2020\n",
            "\n",
            "QUESTION: When was COVID-19 declared a pandemic?\n",
            "* The World Health Organization (WHO) declared the coronavirus outbreak a public health emergency of international concern (PHEIC) on 30th January 2020 and a pandemic on 11th March 2020.\n",
            "* It was first identified in December 2019 in Wuhan, China, and has resulted in an ongoing pandemic.\n",
            "* Out of 14 contacts two were symptomatic and found negative for COVID-19.\n",
            "\n",
            "Answer Type: DATE\n",
            "ANSWER: 11th March 2020\n",
            "\n",
            "QUESTION: How apart should people stay?\n",
            "* Distancing guidelines also include that people stay at least 6 feet (1.8 m) apart.\n",
            "* More than 4.33 million people have recovered.\n",
            "* People can transmit the virus without showing symptoms, but it is unclear how often this happens.\n",
            "\n",
            "ANSWER TYPE: DATE\n",
            "Distancing guidelines also include that people stay at least 6 feet (1.8 m) apart.\n",
            "\n",
            "QUESTION: How many people have recovered till now?\n",
            "* More than 4.33 million people have recovered.\n",
            "* People can transmit the virus without showing symptoms, but it is unclear how often this happens.\n",
            "* Distancing guidelines also include that people stay at least 6 feet (1.8 m) apart.\n",
            "\n",
            "ANSWER TYPE: CARDINAL\n",
            "ANSWER: More than 4.33 million\n",
            "\n",
            "QUESTION: How many cases have been reported?\n",
            "* As of 21st  June 2020, more than 8.75 million cases have been reported across 188 countries and territories, resulting in more than 463,000 deaths.\n",
            "* They remain infectious an estimated seven to twelve days in moderate cases and an average of two weeks in severe cases.\n",
            "* The first confirmed case has been traced back to 17 November 2019.\n",
            "\n",
            "Answer Type: CARDINAL\n",
            "ANSWER: more than 8.75 million\n",
            "\n",
            "QUESTION: How many deaths have occured in various countries?\n",
            "* Local transmission of the disease has occurred in most countries across all six WHO regions.\n",
            "* Transmission without symptoms does occur.\n",
            "* As of 21st  June 2020, more than 8.75 million cases have been reported across 188 countries and territories, resulting in more than 463,000 deaths.\n",
            "\n",
            "Answer Type: CARDINAL\n",
            "ANSWER: more than 463,000\n",
            "\n",
            "QUESTION: In how many World Health Organization zones local transmission has occuerd?\n",
            "* According to the World Health Organization (WHO), there are no vaccines nor specific antiviral treatments for COVID-19.\n",
            "* Local transmission of the disease has occurred in most countries across all six WHO regions.\n",
            "* The World Health Organization (WHO) declared the coronavirus outbreak a public health emergency of international concern (PHEIC) on 30th January 2020 and a pandemic on 11th March 2020.\n",
            "\n",
            "ANSWER TYPE: CARDINAL\n",
            "ANSWER: six\n",
            "\n",
            "QUESTION: Cases have been reported in how many countries?\n",
            "* As of 21st  June 2020, more than 8.75 million cases have been reported across 188 countries and territories, resulting in more than 463,000 deaths.\n",
            "* Local transmission of the disease has occurred in most countries across all six WHO regions.\n",
            "* They remain infectious an estimated seven to twelve days in moderate cases and an average of two weeks in severe cases.\n",
            "\n",
            "Answer Type: CARDINAL\n",
            "ANSWER: 188\n",
            "\n",
            "QUESTION: How many countries have reported cases?\n",
            "* As of 21st  June 2020, more than 8.75 million cases have been reported across 188 countries and territories, resulting in more than 463,000 deaths.\n",
            "* Local transmission of the disease has occurred in most countries across all six WHO regions.\n",
            "* They remain infectious an estimated seven to twelve days in moderate cases and an average of two weeks in severe cases.\n",
            "\n",
            "Answer Type: CARDINAL\n",
            "ANSWER: 188\n",
            "\n",
            "QUESTION: How long should I wash my hands?\n",
            "* The CDC also recommends that individuals wash hands often with soap and water for at least 20 seconds, especially after going to the toilet or when hands are visibly dirty, before eating and after blowing one's nose, coughing or sneezing.\n",
            "* Recommended measures to prevent infection include frequent hand washing, maintaining physical distance from others (especially from those with symptoms), quarantine (especially for those with symptoms), covering coughs, and keeping unwashed hands away from the face.\n",
            "* The droplets usually fall to the ground or onto surfaces rather than travelling through air over long distances.\n",
            "\n",
            "ANSWER TYPE: DATE\n",
            "The CDC also recommends that individuals wash hands often with soap and water for at least 20 seconds, especially after going to the toilet or when hands are visibly dirty, before eating and after blowing one's nose, coughing or sneezing.\n",
            "\n",
            "QUESTION: What are the common symptoms of COVID-19?\n",
            "ANSWER TYPE: DESCRIPTIVE\n",
            "* Fever is the most common symptom of COVID-19, but is highly variable in severity and presentation, with some older, immunocompromised, or critically ill people not having fever at all.\n",
            "* As is common with infections, there is a delay between the moment a person is first infected and the time he or she develops symptoms.\n",
            "* Common symptoms include fever, cough, fatigue, shortness of breath, and loss of smell and taste.\n",
            "Fever is the most common symptom of COVID-19, but is highly variable in severity and presentation, with some older, immunocompromised, or critically ill people not having fever at all.\n",
            "As is common with infections, there is a delay between the moment a person is first infected and the time he or she develops symptoms.\n",
            "Common symptoms include fever, cough, fatigue, shortness of breath, and loss of smell and taste.\n",
            "\n",
            "QUESTION: What type of masks should I wear?\n",
            "ANSWER TYPE: DESCRIPTIVE\n",
            "* Health officials also stated that medical-grade face masks, such as N95 masks, should only be used by healthcare workers, first responders, and those who directly care for infected individuals.\n",
            "* Several countries have recommended that healthy individuals wear face masks or cloth face coverings (like scarves or bandanas) at least in certain public settings, including China, Hong Kong, Spain, Italy, Russia, and the United States.\n",
            "* Those diagnosed with coronavirus or who believe they may be infected are advised by the CDC to stay home except to get medical care, call ahead before visiting a healthcare provider, wear a face mask before entering the healthcare provider's office and when in any room or vehicle with another person, cover coughs and sneezes with a tissue, regularly wash hands with soap and water and avoid sharing personal household items.\n",
            "Health officials also stated that medical-grade face masks, such as N95 masks, should only be used by healthcare workers, first responders, and those who directly care for infected individuals.\n",
            "Several countries have recommended that healthy individuals wear face masks or cloth face coverings (like scarves or bandanas) at least in certain public settings, including China, Hong Kong, Spain, Italy, Russia, and the United States.\n",
            "Those diagnosed with coronavirus or who believe they may be infected are advised by the CDC to stay home except to get medical care, call ahead before visiting a healthcare provider, wear a face mask before entering the healthcare provider's office and when in any room or vehicle with another person, cover coughs and sneezes with a tissue, regularly wash hands with soap and water and avoid sharing personal household items.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}